{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2017年5月16日 整理之前的程序\n",
    "# 先把用户和产品分别分类后,再和action数据融合\n",
    "# 数据窗口\n",
    "n =10\n",
    "test_size= .6\n",
    "cls = 'tree' #0.773114977823\n",
    "cls = 'bayes' #0.655407710679\n",
    "cls = 'GBDT' #0.841282838622\n",
    "cls = 'lr' #0.831252132378\n",
    "cls = 'svm' #SVM不适用本例\n",
    "cls = 'rf' #0.797884680996\n",
    "cls = 'knn' #0.782668031389\n",
    "resultsfilename = 'results_n' + str(n) + '_cls' + cls +'.csv'\n",
    "samplemult = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 函数设定区\n",
    "# 提取购买行为发生前n天用户行为的特征，用户和产品抽象为类别\n",
    "# \n",
    "def special_predict(n, df_action_all, df_action_special, dict_user_cat, dict_sku_cat, filename):\n",
    "    '''\n",
    "    输入：\n",
    "    n：产生特定行为数据之前n天的数据组成特征（特定用户针对特定产品）\n",
    "    df_action_all：全部行为数据\n",
    "    df_action_special:特定行为数据\n",
    "    输出：\n",
    "    df_per:输出的数据组成特征\n",
    "    df_action_special_index:构成以上数据组成特征的原始数据索引\n",
    "    '''\n",
    "    # df_action_special变为array,加快索引效率\n",
    "    array_user_id = np.array(df_action_special['user_id'])\n",
    "    array_sku_id = np.array(df_action_special['sku_id'])\n",
    "    array_time = np.array(df_action_special['time'])\n",
    "    time = '2016-04-16 00:00:00'\n",
    "    # 时间前移10天\n",
    "    time_s_string = '2016-04-06 00:00:00'\n",
    "    df_action_all = df_action_all[(df_action_all['time'] > time_s_string) & (df_action_all['time'] <= time)]\n",
    "    # 建立特征值DataFrame\n",
    "    df_per = pd.DataFrame(columns=('browser', 'addchar', 'delchar', 'buy', 'fav', 'click', 'user_cat', 'sku_cat'))\n",
    "    \n",
    "    # 循环建立各个specail行为前n天的特征值\n",
    "    for i in range(len(df_action_special)):\n",
    "        if i%10000 == 0:\n",
    "            print i\n",
    "        user = array_user_id[i]\n",
    "        # print user,df1[df1['user_id'] == user]\n",
    "        user_cat = dict_user_cat[user]\n",
    "        sku = array_sku_id[i]\n",
    "        # print sku,df_pb[df_pb['sku_id'] == sku]\n",
    "        sku_cat = dict_sku_cat[sku]\n",
    "        user_sku = user * 100000000 + sku\n",
    "        # 筛选购买动作前n天的数据\n",
    "        df_action_p = df_action_all[df_action_all['user_sku'] == user_sku]\n",
    "        # print len(df_action_nobuy)\n",
    "        # 提取特征值,各项动作的次数\n",
    "        # print len(df_action_nobuy)\n",
    "        df_action_type_counts = df_action_p['type'].value_counts()\n",
    "        # 处理异常数据\\缺失值\n",
    "        for k in range(1,7):\n",
    "            try:\n",
    "                df_action_type_counts[k]\n",
    "            except:\n",
    "                df_action_type_counts[k] = 0\n",
    "        # 写入一行数据特征值\n",
    "        df_per.loc[i]={'user_cat':user_cat,'sku_cat':sku_cat,'browser':df_action_type_counts[1],'addchar':df_action_type_counts[2],'delchar':df_action_type_counts[3],'buy':df_action_type_counts[4],'fav':df_action_type_counts[5],'click':df_action_type_counts[6]}\n",
    "    return df_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 函数设定区\n",
    "# 提取购买行为发生前n天用户行为的特征，用户和产品抽象为类别\n",
    "# \n",
    "def special_per(n, df_action_all, df_action_special, dict_user_cat, dict_sku_cat, filename):\n",
    "    '''\n",
    "    输入：\n",
    "    n：产生特定行为数据之前n天的数据组成特征（特定用户针对特定产品）\n",
    "    df_action_all：全部行为数据\n",
    "    df_action_special:特定行为数据\n",
    "    输出：\n",
    "    df_per:输出的数据组成特征\n",
    "    df_action_special_index:构成以上数据组成特征的原始数据索引\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # df_action_special变为array,加快索引效率\n",
    "    array_user_id = np.array(df_action_special['user_id'])\n",
    "    array_sku_id = np.array(df_action_special['sku_id'])\n",
    "    array_time = np.array(df_action_special['time'])\n",
    "    \n",
    "    # 建立特征值DataFrame\n",
    "    df_per = pd.DataFrame(columns=('browser', 'addchar', 'delchar', 'buy', 'fav', 'click', 'user_cat', 'sku_cat'))\n",
    "    \n",
    "    # 循环建立各个specail行为前n天的特征值\n",
    "    for i in range(len(df_action_special)):\n",
    "        print i\n",
    "        user = array_user_id[i]\n",
    "        # print user,df1[df1['user_id'] == user]\n",
    "        user_cat = dict_user_cat[user]\n",
    "        sku = array_sku_id[i]\n",
    "        # print sku,df_pb[df_pb['sku_id'] == sku]\n",
    "        sku_cat = dict_sku_cat[sku]\n",
    "        time = array_time[i]\n",
    "        # 时间前移10天\n",
    "        time_s_datetime = pd.datetime.strptime(time , '%Y-%m-%d %H:%M:%S') - pd.Timedelta(days = n)\n",
    "        time_s_string = pd.datetime.strftime(time_s_datetime , '%Y-%m-%d %H:%M:%S')\n",
    "        # 筛选购买动作前n天的数据\n",
    "        df_action_p = df_action_all[(df_action_all['user_id'] == user) & (df_action_all['sku_id'] == sku) & (df_action_all['time'] > time_s_string) & (df_action_all['time'] <= time)]\n",
    "        # 动作数据集记录以上数据索引,标记为已使用过的数据,以便之后删除\n",
    "        if i > 0:\n",
    "            df_action_special_index = df_action_special_index.append(df_action_p.index)\n",
    "        else:\n",
    "            df_action_special_index = df_action_p.index\n",
    "        # print len(df_action_nobuy)\n",
    "        # 提取特征值,各项动作的次数\n",
    "        # print len(df_action_nobuy)\n",
    "        df_action_type_counts = df_action_p['type'].value_counts()\n",
    "        # 处理异常数据\\缺失值\n",
    "        for k in range(1,7):\n",
    "            try:\n",
    "                df_action_type_counts[k]\n",
    "            except:\n",
    "                df_action_type_counts[k] = 0\n",
    "        # 写入一行数据特征值\n",
    "        df_per.loc[i]={'user_cat':user_cat,'sku_cat':sku_cat,'browser':df_action_type_counts[1],'addchar':df_action_type_counts[2],'delchar':df_action_type_counts[3],'buy':df_action_type_counts[4],'fav':df_action_type_counts[5],'click':df_action_type_counts[6]}\n",
    "    df_per.to_csv(filename)\n",
    "    df_action_special_index = df_action_special_index.drop_duplicates()\n",
    "    return df_per, df_action_special_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----以上是必备函数区域-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "# 设定数据存储文件位置\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 文件列表\n",
    "ACTION_201602_FILE = \"JData/JData_Action_201602.csv\"\n",
    "ACTION_201603_FILE = \"JData/JData_Action_201603.csv\"\n",
    "ACTION_201604_FILE = \"JData/JData_Action_201604.csv\"\n",
    "COMMENT_FILE = \"JData/JData_Comment.csv\"\n",
    "PRODUCT_FILE = \"JData/JData_Product.csv\"\n",
    "USER_FILE = \"JData/JData_User.csv\"\n",
    "USER_TABLE_FILE = \"JData/JData_Table_User.csv\"\n",
    "PRODUCT_TABLE_FILE = \"JData/JData_Table_Product.csv\"\n",
    "BEHAVIOR_TABLE_FILE = \"JData/JData_Table_Behavior.csv\"\n",
    "DEMO = \"demo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用户数据读取及处理\n",
    "df_user = pd.read_csv(USER_FILE)\n",
    "# 用户年龄替换成数值\n",
    "def user_age_map(user_age):\n",
    "    USER_AGE_MAP = {u'15岁以下'.encode('gbk'): 1,\n",
    "                u'16-25岁'.encode('gbk'): 2,\n",
    "                u'26-35岁'.encode('gbk'): 3,\n",
    "                u'36-45岁'.encode('gbk'): 4,\n",
    "                u'46-55岁'.encode('gbk'): 5,\n",
    "                u'56岁以上'.encode('gbk'): 6,\n",
    "                u'-1'.encode('gbk'): 0}\n",
    "    try:\n",
    "        USER_AGE_MAP[user_age]\n",
    "        # print outputt\n",
    "    except:\n",
    "        outputt = user_age\n",
    "    else:\n",
    "        outputt = USER_AGE_MAP[user_age]\n",
    "    # print outputt\n",
    "    return outputt\n",
    "# print user_age_map(df_user.iloc[0, 1])\n",
    "df1 = df_user.applymap(user_age_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 聚类用户数据\n",
    "# 不用,直接根据特征值分类吧,分成93类?\n",
    "def age_sex_string(inputt):\n",
    "    try:\n",
    "        str(int(inputt))\n",
    "    except:\n",
    "        return '0'\n",
    "    else:\n",
    "        return str(int(inputt))\n",
    "def regtm_string(inputt):\n",
    "    inputt = str(inputt)\n",
    "    try:\n",
    "        inputt[:4]\n",
    "    except:\n",
    "        return '0000'\n",
    "    else:\n",
    "        return inputt[:4]\n",
    "def lvcd_string(inputt):\n",
    "    return str(inputt)\n",
    "# df1['user_cat'] = df1['age'].map(age_sex_string) + df1['sex'].map(age_sex_string) + df1['user_lv_cd'].map(lvcd_string) + df1['user_reg_tm'].map(regtm_string)\n",
    "df1['user_cat'] = df1['age'].map(age_sex_string) + df1['sex'].map(age_sex_string) + df1['user_lv_cd'].map(lvcd_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 产品数据读取及处理\n",
    "df_product = pd.read_csv(PRODUCT_FILE)\n",
    "# print df_product.head(20)\n",
    "\n",
    "# 评价数据\n",
    "df_comment = pd.read_csv(COMMENT_FILE)\n",
    "# print df_comment.head()\n",
    "\n",
    "# 产品和评价数据融合\n",
    "product_behavior = pd.merge(df_product,df_comment, on=['sku_id'], how = 'outer')\n",
    "# print product_behavior.head(50)\n",
    "df_pb = product_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 聚类产品数据\n",
    "# 不用,直接根据特征值分类吧,分成367类\n",
    "def int_to_string(inputt):\n",
    "    try:\n",
    "        str(int(inputt))\n",
    "    except:\n",
    "        return '0'\n",
    "    else:\n",
    "        return str(int(inputt))\n",
    "# df1['user_cat'] = df1['age'].map(age_sex_string) + df1['sex'].map(age_sex_string) + df1['user_lv_cd'].map(lvcd_string) + df1['user_reg_tm'].map(regtm_string)\n",
    "df_pb['prod_cat'] = df_pb['a1'].map(int_to_string) + df_pb['a2'].map(int_to_string) + df_pb['a3'].map(int_to_string) + df_pb['cate'].map(int_to_string) + df_pb['brand'].map(int_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用户与分类之间建立词典\n",
    "df_user_cat = df1.loc[:,['user_id','user_cat']]\n",
    "dict_user_cat = df_user_cat.set_index('user_id')['user_cat'].to_dict()\n",
    "# 产品与分类之间建立词典\n",
    "df_sku_cat = df_pb.loc[:,['sku_id','sku_cat']]\n",
    "df_sku_cat = df_sku_cat.fillna('00000')\n",
    "dict_sku_cat = df_sku_cat.set_index('sku_id')['sku_cat'].to_dict()\n",
    "n=10\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取行为数据\n",
    "df_action_201602 = pd.read_csv(ACTION_201602_FILE)\n",
    "df_action_201603 = pd.read_csv(ACTION_201603_FILE)\n",
    "df_action_201604 = pd.read_csv(ACTION_201604_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去除重复行\n",
    "df_action_201602 = df_action_201602.drop_duplicates()\n",
    "print len(df_action_201602)\n",
    "# 去除其他品类数据\n",
    "df_action_201602 = df_action_201602[df_action_201602['cate'] == 8]\n",
    "print len(df_action_201602)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去除重复行\n",
    "df_action_201603 = df_action_201603.drop_duplicates()\n",
    "print len(df_action_201603)\n",
    "# 去除其他品类数据\n",
    "df_action_201603 = df_action_201603[df_action_201603['cate'] == 8]\n",
    "print len(df_action_201603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去除重复行\n",
    "df_action_201604 = df_action_201604.drop_duplicates()\n",
    "print len(df_action_201604)\n",
    "# 去除其他品类数据\n",
    "df_action_201604 = df_action_201604[df_action_201604['cate'] == 8]\n",
    "print len(df_action_201604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置总数据集合\n",
    "df_action_all = df_action_201602\n",
    "# 提取有购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_buy = df_action_all[df_action_all['type'] == 4]\n",
    "filename_buy = '201602buy_per.csv'\n",
    "%time df_per, df_action_buy_index = special_per(n, df_action_all, df_action_buy, dict_user_cat, dict_sku_cat, filename_buy)\n",
    "# 提取无购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_all_nobuy = df_action_all.drop(df_action_buy_index)\n",
    "nobuy_sample_n = len(df_action_buy)\n",
    "df_action_nobuy = df_action_all.sample(nobuy_sample_n * samplemult)\n",
    "filename_nobuy = '201602nobuy_per.csv'\n",
    "df_per, df_action_nobuy_index = special_per(n, df_action_all_nobuy, df_action_nobuy, dict_user_cat, dict_sku_cat, filename_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置总数据集合\n",
    "df_action_all = df_action_201603\n",
    "# 提取有购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_buy = df_action_all[df_action_all['type'] == 4]\n",
    "filename_buy = '201603buy_per.csv'\n",
    "df_per, df_action_buy_index = special_per(n, df_action_all, df_action_buy, dict_user_cat, dict_sku_cat, filename_buy)\n",
    "# 提取无购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_all_nobuy = df_action_all.drop(df_action_buy_index)\n",
    "nobuy_sample_n = len(df_action_buy)\n",
    "df_action_nobuy = df_action_all.sample(nobuy_sample_n * samplemult)\n",
    "filename_nobuy = '201603nobuy_per.csv'\n",
    "df_per, df_action_nobuy_index = special_per(n, df_action_all_nobuy, df_action_nobuy, dict_user_cat, dict_sku_cat, filename_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置总数据集合\n",
    "df_action_all = df_action_201604\n",
    "# 提取有购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_buy = df_action_all[df_action_all['type'] == 4]\n",
    "filename_buy = '201604buy_per.csv'\n",
    "df_per, df_action_buy_index = special_per(n, df_action_all, df_action_buy, dict_user_cat, dict_sku_cat, filename_buy)\n",
    "# 提取无购买行为的用户在购买行为发生前n天的特征\n",
    "df_action_all_nobuy = df_action_all.drop(df_action_buy_index)\n",
    "nobuy_sample_n = len(df_action_buy)\n",
    "df_action_nobuy = df_action_all.sample(nobuy_sample_n * samplemult)\n",
    "filename_nobuy = '201604nobuy_per.csv'\n",
    "df_per_nobuy, df_action_nobuy_index = special_per(n, df_action_all_nobuy, df_action_nobuy, dict_user_cat, dict_sku_cat, filename_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存04月份的未购买数据，这是用于预测的基础数据库\n",
    "action_nobuy_index = pd.DataFrame(np.array(df_action_nobuy_index))\n",
    "action_nobuy_index.to_csv('201604nobuyindex.csv')\n",
    "df_action_all_nobuy = df_action_all_nobuy.drop(df_action_nobuy_index)\n",
    "df_action_all_nobuy.to_csv('201604nobuyaction.csv')\n",
    "print len(df_action_all_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----以上是数据处理部分------\n",
    "# -----以下是数据预测部分------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练数据比例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取所有已保存的数据\n",
    "filename_all = ['201602nobuy_per.csv', '201603buy_per.csv', '201603nobuy_per.csv', '201604buy_per.csv', '201604nobuy_per.csv']\n",
    "df_per_all = pd.read_csv('201602buy_per.csv', header = 0, index_col = 0)\n",
    "for item in filename_all:\n",
    "    df_per_all = pd.concat([df_per_all, pd.read_csv(item, header = 0, index_col = 0)])\n",
    "df_per_all.to_csv('df_per_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 转变成sklearn可以使用的数据库\n",
    "X = np.array(df_per_all.drop('buy',axis =1))\n",
    "y = np.array(df_per_all['buy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用以上数据训练DecisionTreeClassifier模型,训练出数据模型\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cls == 'tree':\n",
    "    from sklearn import tree\n",
    "    clf =tree.DecisionTreeClassifier()\n",
    "if cls == 'bayes':\n",
    "    from sklearn import naive_bayes\n",
    "    clf = naive_bayes.GaussianNB()\n",
    "if cls == 'GBDT':\n",
    "    from sklearn import ensemble\n",
    "    clf = ensemble.GradientBoostingClassifier()\n",
    "if cls == 'lr':\n",
    "    from sklearn import linear_model\n",
    "    clf = linear_model.LogisticRegressionCV()\n",
    "if cls = 'svm':\n",
    "    # from sklearn import svm\n",
    "    # clf = svm.SVC()\n",
    "if cls = 'rf':\n",
    "    from sklearn import ensemble\n",
    "    clf = ensemble.RandomForestClassifier()\n",
    "if cls = 'knn':\n",
    "    from sklearn import neighbors\n",
    "    clf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "pre_prob = clf.predict_proba(X_test)\n",
    "pre_log_prob = clf.predict_log_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import  accuracy_score\n",
    "print accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------以下是预测数据准备------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_action_all_nobuy = pd.read_csv('201604nobuyaction.csv', header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 提取2016-04-16到2016-04-20用户行为\n",
    "# 设置总数据集合\n",
    "df_action_all = df_action_all_nobuy\n",
    "print len(df_action_all),len(df_action_201604)\n",
    "# 筛选出预测用户和预测产品的相关数据\n",
    "df_action_all = df_action_all[(df_action_all['user_id'].isin(dict_user_cat.keys())) & (df_action_all['sku_id'].isin(dict_sku_cat.keys()))]\n",
    "print df_action_all.head()\n",
    "print len(df_action_all)\n",
    "# 筛选不筛选是一样一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用用户产品对作为索引\n",
    "df_action_all['user_sku'] = df_action_all['user_id']*100000000 + df_action_all['sku_id']\n",
    "df_user_sku = df_action_all.drop_duplicates(['user_sku'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 补全数据，形成预测对象数据，所有的4月份用户产品对\n",
    "df_user_sku['time'] = '2016-04-16 00:00:00'\n",
    "df_user_sku['type'] = 0\n",
    "print df_user_sku, len(df_user_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存用户数据对\n",
    "df_user_sku.to_csv('201604_user_sku.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 寻找特征数据\n",
    "filename_unknown = '20160416unknown_per.csv'\n",
    "df_per_unknown = special_predict(n, df_action_all, df_user_sku, dict_user_cat, dict_sku_cat, filename_unknown)\n",
    "df_per_unknown.to_csv(filename_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------进行数据预测--------\n",
    "df_user_sku = pd.read_csv('201604_user_sku.csv', header = 0, index_col = 0)\n",
    "df_per_unknown = pd.read_csv(filename_unknown, header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用之前的模型进行数据预测\n",
    "X_unknown = np.array(df_per_unknown.drop('buy',axis =1))\n",
    "print X_unknown\n",
    "predictions = clf.predict(X_unknown)\n",
    "pre_prob = clf.predict_proba(X_unknown)\n",
    "print predictions,pre_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测结果和用户产品数据融合，以便接下来处理\n",
    "df_user_sku['buy'] = predictions\n",
    "df_user_sku['buy_prob'] = pre_prob[:,1]\n",
    "print df_user_sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 筛选出购买结果数据\n",
    "df_buy = df_user_sku[df_user_sku['buy'] == 1]\n",
    "print df_buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 筛选最佳结果 函数\n",
    "def best_sku(df):\n",
    "    return (df.sort(['buy_prob'],ascending = False)).iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 分类统计选取最佳结果\n",
    "grouped = df_buy.groupby(['user_id'])\n",
    "results = grouped.apply(best_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据转换函数\n",
    "def int_to_str(id):\n",
    "    return str(int(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 形成数据结果\n",
    "results = results.loc[:,['user_id','sku_id']]\n",
    "results['user_id'] = results['user_id'].apply(int_to_str)\n",
    "results.to_csv(resultsfilename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
